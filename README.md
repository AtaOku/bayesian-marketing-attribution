# ðŸ” Fashion E-Commerce Return Root Cause Diagnosis

**Bayesian Network Backward Inference for Diagnosing Hidden Return Reasons**

> Course: Fundamentals of Artificial Intelligence (IN2406) Â· TUM  
> Author: Ata Okuzcuoglu Â· MSc Management & Technology (Marketing + CS)  
> Context: Personal project applying course concepts to a real marketing problem

[![Streamlit App](https://static.streamlit.io/badges/streamlit_badge_black_white.svg)](https://bayesian-marketing-attribution-model.streamlit.app)

---

## The Problem

Fashion e-commerce suffers from return rates of **25-40%**, costing the industry **$218 billion globally** (Radial, 2024). Analytics dashboards show *which* items are returned â€” but cannot answer **why**.

Customer-reported reasons are unreliable: surveys show only 30-40% completion, and customers frequently misreport the true reason. Meanwhile, the actual breakdown (Coresight, 2023; Rocket Returns, 2025):

| Root Cause | Share of Returns |
|---|---|
| Size / Fit Mismatch | 53â€“70% |
| Style / Expectation Gap | 16â€“23% |
| Quality / Damage | 10â€“13% |
| Impulse / Buyer's Regret | 8â€“15% |
| Intentional Bracketing | ~15% (multi-brand) |

## The Solution: Backward Inference

This tool uses a **Bayesian Network** to reason *backward* from observed signals to hidden causes:

```
Given: returned = Yes + observable order signals
Infer: P(root_cause | evidence) for 5 competing causes
Find:  Which cause has the highest diagnostic lift?
```

**Why BN and not regression?** Regression predicts *P(returned | features)* â€” whether a return happens. A BN computes *P(cause | returned=Yes, signals)* â€” **why** it happened. This is the information merchandising teams need.

## Network Architecture

```
OBSERVABLE (12 nodes)              ROOT CAUSES (5)              OUTCOME
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•            â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•              â•â•â•â•â•â•â•

size_sensitive_category â”€â”€â”
is_first_purchase â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ ðŸ‘— SIZE_MISMATCH â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
viewed_size_guide â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â”‚
mobile_purchase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
                                                          â”‚
premium_price â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
is_first_purchase â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ ðŸ“¸ EXPECTATION_GAP â”€â”€â”€â”€â”€â”€â”€â”¤
mobile_purchase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”œâ”€â”€â†’ RETURNED
                                                          â”‚    (Noisy-OR)
purchased_on_discount â”€â”€â”€â”€â”                               â”‚
social_media_referral â”€â”€â”€â”€â”¼â”€â”€â†’ ðŸ’¸ IMPULSE_REGRET â”€â”€â”€â”€â”€â”€â”€â”€â”¤
mobile_purchase â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤                               â”‚
young_customer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                               â”‚
                                                          â”‚
multi_size_order â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
young_customer â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â†’ ðŸ”„ BRACKETING â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
high_return_history â”€â”€â”€â”€â”€â”€â”˜                               â”‚
                                                          â”‚
slow_delivery â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                               â”‚
multiple_items_in_order â”€â”€â”¼â”€â”€â†’ ðŸ“¦ QUALITY/DAMAGE â”€â”€â”€â”€â”€â”€â”€â”€â”˜
premium_price â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

**18 nodes Â· 22 edges Â· All binary Â· 2Â¹â¸ = 262,144 states Â· Exact inference**

## Key Features

- **Root Cause Diagnosis** â€” Set evidence, see which of 5 causes has the highest posterior probability
- **Diagnostic Lift** â€” P(cause|evidence) / P(cause) reveals which cause the evidence supports most
- **What-If Simulation** â€” Change one signal and see how return probability shifts
- **Sensitivity Analysis** â€” Tornado chart showing individual signal impact on return probability; reveals Multi-Size Order as dominant driver (+50% swing)
- **Continuous Input Mode** â€” Enter exact values (discount %, age, price â‚¬, delivery days) instead of Yes/No â€” the model adjusts CPT weights via linear interpolation
- **Parameter Calibration** â€” Adjust all 42 parameters (priors, CPT increments, Noisy-OR strengths) via UI sliders or CSV upload to match your own platform's data
- **Academic Methodology Tab** â€” Full formal definition, CPT calibration, Noisy-OR model, sensitivity analysis, structural constraints
- **17 Research Citations** â€” Every CPT parameter grounded in industry data
- **6 Persona-Based Scenarios** â€” Horizontal button selector with persona names (e.g. *The Instagram Impulse Shopper*), signal detail cards, plus custom mode via sidebar toggle

## Continuous Input Mode

Real-world order signals aren't binary. A 10% discount and a 60% discount both count as "Yes" â€” but their effect on impulse behavior is very different.

In Custom mode, toggle **Continuous Mode** to enter exact values for 4 key signals:

| Signal | Input | Threshold | Weight Range | Effect |
|---|---|---|---|---|
| Discount | 0â€“80% | >0% â†’ Yes | 0.0Ã— â€“ 1.8Ã— | Modulates impulse_regret increment |
| Customer Age | 16â€“70 years | <40 â†’ Yes | 0.2Ã— â€“ 1.5Ã— | Modulates impulse + bracketing |
| Product Price | â‚¬5â€“500 | >â‚¬100 â†’ Yes | 0.3Ã— â€“ 1.5Ã— | Modulates expectation + quality |
| Delivery Time | 1â€“14 days | >5 days â†’ Yes | 0.0Ã— â€“ 1.5Ã— | Modulates quality/damage |

The weight modulates the CPT increment via linear interpolation between research-grounded reference points. This composes with custom parameters from the Calibration tab:

```
effective_increment = calibrated_increment Ã— continuous_weight
```

The BN structure stays binary (18 nodes, 22 edges, same inference). Only the CPT values are modulated at build time.

## Parameter Calibration

The default parameters are grounded in 17 industry research citations â€” but every platform is different. A fast-fashion brand might have 38% return rates with 85% mobile traffic; a luxury brand might have 18% returns and 40% mobile.

The **Calibration** tab provides three modes:

| Mode | What You Adjust | Use Case |
|---|---|---|
| **Quick Mode** | 12 observable priors + 6 Noisy-OR strengths | "Our mobile share is 78%, not 65%" |
| **Advanced Mode** | All 24 CPT risk increments per root cause | "Size-sensitive category contributes +15%, not +12%" |
| **CSV Import/Export** | All 42 parameters via spreadsheet | Team calibration workflow, version control |

All other tabs (Diagnosis, What-If, Methodology) update live with your custom parameters. A green banner indicates when custom parameters are active.

## Example Diagnoses

| Scenario | Top Diagnosis | Lift |
|---|---|---|
| The Size-Blind First-Timer | ðŸ‘— Size Mismatch | 3.69x |
| The Try-At-Home Bracketer | ðŸ”„ Bracketing | 12.05x |
| The Instagram Impulse Shopper | ðŸ’¸ Impulse Regret | 3.62x |
| The Frustrated Late Receiver | ðŸ“¦ Quality/Fulfillment | 5.56x |

## Tech Stack

- **Engine:** Custom BayesNet class with cached joint table inference â€” full joint computed once (2.5s), subsequent queries <20ms via NumPy boolean masking
- **Frontend:** Streamlit with 6 tabs (Diagnosis, What-If, Sensitivity, Calibration, Methodology, References)
- **No external ML libraries** â€” Built from first principles to demonstrate understanding
- **42 parameterized CPT values** â€” Extracted into a structured config with CSV import/export
- **Structural constraint:** Bracketing impossible without multi-size order (P=0.00)

## Running Locally

```bash
pip install -r requirements.txt
streamlit run app.py
```

## References

See the full References tab in the app for 17 citations. Key sources:

1. Coresight Research (2023). "The True Cost of Apparel Returns"
2. Radial (2024). "Tech Takes on E-Commerce's $218 Billion Returns Problem"
3. Rocket Returns (2025). "Ecommerce Return Rates: Complete Industry Analysis"
4. AfterShip (2024). "Returns: Fashion's $218 Billion Problem"
5. Landmark Global (2025). "Wardrobing & Bracketing: Serial Returners"
6. Russell & Norvig (2021). *AI: A Modern Approach*, 4th ed., Ch. 13-14

## Part of the MarTech Ã— AI Portfolio

This is **Project 2** in a portfolio demonstrating AI techniques applied to marketing:
- Project 1: CSP-Based Campaign & Budget Planner
- **Project 2: BN Return Root Cause Diagnosis** â† You are here
- Project 3: HMM-Based Customer Lifecycle Segmentation (planned)
- Project 4: MDP for Dynamic Pricing Strategy (planned)

---

*Built by Ata Okuzcuoglu Â· TUM MSc Management & Technology Â· 2025*
